{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e99894-0aa7-4315-9cb6-6370384756ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from sklearn.metrics import precision_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, LearningRateScheduler\n",
    "\n",
    "# Set the image size and other constants\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "NUM_CLASSES = 1  # Single class for binary segmentation\n",
    "\n",
    "# Suppress TensorFlow warnings and error messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "def load_dataset(image_dir, mask_dir, img_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for image_name in tqdm(os.listdir(image_dir)):\n",
    "        if image_name.lower().endswith(('.jpeg', '.jpg')):\n",
    "            base_name = os.path.splitext(image_name)[0]\n",
    "            mask_name = f\"{base_name}_mask.jpg\"\n",
    "            \n",
    "            img_path = os.path.join(image_dir, image_name)\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            \n",
    "            if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "                try:\n",
    "                    image = load_img(img_path, target_size=img_size)\n",
    "                    mask = load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n",
    "                    \n",
    "                    image = img_to_array(image)\n",
    "                    mask = img_to_array(mask)\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    masks.append(mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"Mask not found for image: {image_name}\")\n",
    "    \n",
    "    images = np.array(images, dtype=np.float32) / 255.0\n",
    "    masks = np.array(masks, dtype=np.float32) / 255.0\n",
    "\n",
    "    masks = (masks > 0.5).astype(np.uint8)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Define directories\n",
    "train_image_dir = '/home/syam.varnatt/THESIS/images/train/images'\n",
    "train_mask_dir = '/home/syam.varnatt/THESIS/images/train/masks'\n",
    "val_image_dir = '/home/syam.varnatt/THESIS/images/val/images'\n",
    "val_mask_dir = '/home/syam.varnatt/THESIS/images/val/masks'\n",
    "SAVE_DIRECTORY = '/home/syam.varnatt/THESIS/comparison-model/deeplab/normal/results'\n",
    "os.makedirs(SAVE_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "train_images, train_masks = load_dataset(train_image_dir, train_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Training dataset loaded completely\")\n",
    "val_images, val_masks = load_dataset(val_image_dir, val_mask_dir, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(\"Validation dataset loaded completely\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ab5c9-05e0-4a94-9154-c011e1426356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLabV3+ architecture \n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source, target = inputs\n",
    "        target_size = tf.shape(target)[1:3]\n",
    "        return tf.image.resize(source, target_size)\n",
    "\n",
    "def aspp_block(x, num_filters):\n",
    "    # ASPP branch 1: 1x1 convolution\n",
    "    x1 = tf.keras.layers.Conv2D(num_filters, (1, 1), padding='same', use_bias=False)(x)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.ReLU()(x1)\n",
    "\n",
    "    # ASPP branch 2: 3x3 convolution with dilation rate 6\n",
    "    x2 = tf.keras.layers.Conv2D(num_filters, (3, 3), dilation_rate=6, padding='same', use_bias=False)(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.ReLU()(x2)\n",
    "\n",
    "    # ASPP branch 3: Global average pooling followed by 1x1 convolution\n",
    "    x3 = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x3 = tf.keras.layers.Reshape((1, 1, x.shape[-1]))(x3)\n",
    "    x3 = tf.keras.layers.Conv2D(num_filters, (1, 1), padding='same', use_bias=False)(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.ReLU()(x3)\n",
    "\n",
    "    # Resize the pooled features to match the size of other branches using a custom layer\n",
    "    x3 = ResizeLayer()([x3, x1])\n",
    "\n",
    "    # Concatenate all the branches\n",
    "    x = tf.keras.layers.Concatenate()([x1, x2, x3])\n",
    "    return x\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3)\n",
    "    )\n",
    "\n",
    "    # Extract feature map from the last block of MobileNetV2\n",
    "    x = base_model.get_layer('block_13_expand_relu').output\n",
    "\n",
    "    # Apply simplified ASPP block\n",
    "    x = aspp_block(x, 64)  # Reduced number of filters\n",
    "\n",
    "    # Dynamically upsample the output to match the original input size / 4 using a custom layer\n",
    "    x = ResizeLayer()([x, base_model.input])\n",
    "\n",
    "    # Extract low-level features from an earlier layer of MobileNetV2\n",
    "    low_level_feature = base_model.get_layer('block_3_expand_relu').output\n",
    "    low_level_feature = tf.keras.layers.Conv2D(16, (1, 1), padding='same', use_bias=False)(low_level_feature)  # Reduced number of filters\n",
    "    low_level_feature = tf.keras.layers.BatchNormalization()(low_level_feature)\n",
    "    low_level_feature = tf.keras.layers.ReLU()(low_level_feature)\n",
    "\n",
    "    # Resize the low-level features to match the size of the high-level features using a custom layer\n",
    "    low_level_feature = ResizeLayer()([low_level_feature, x])\n",
    "\n",
    "    # Concatenate the high-level and low-level features\n",
    "    x = tf.keras.layers.Concatenate()([x, low_level_feature])\n",
    "\n",
    "    # Further processing with a few convolutional layers\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(x)  # Reduced number of filters\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Apply dropout\n",
    "    #x = tf.keras.layers.Dropout(0.2)(x)  # Reduced dropout rate\n",
    "\n",
    "    # Final 1x1 convolution to produce the output segmentation map\n",
    "    x = tf.keras.layers.Conv2D(num_classes, (1, 1), padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('sigmoid')(x)  # Add sigmoid activation for binary segmentation\n",
    "\n",
    "    # Final upsampling to match the input image size using a custom layer\n",
    "    x = ResizeLayer()([x, base_model.input])\n",
    "\n",
    "    # Define the model\n",
    "    return tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Enable mixed precision\n",
    "#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Instantiate the DeepLabV3+ model\n",
    "model = DeeplabV3Plus((IMG_HEIGHT, IMG_WIDTH), NUM_CLASSES)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "#def lr_schedule(epoch, lr):\n",
    " #   return lr * 0.9  # Reduce learning rate by 10% every epoch\n",
    "\n",
    "#lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Compile the model with appropriate loss and metrics\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d265a-ad23-47c0-a3fb-73af477be0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_images, val_masks, save_dir, num_samples=3):\n",
    "        super(VisualizationCallback, self).__init__()\n",
    "        self.val_images = val_images\n",
    "        self.val_masks = val_masks\n",
    "        self.save_dir = save_dir\n",
    "        self.num_samples = num_samples  # Number of samples to visualize per epoch\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Randomly select a few samples to visualize predictions\n",
    "        idxs = np.random.choice(len(self.val_images), self.num_samples, replace=False)\n",
    "        images_to_show = self.val_images[idxs]\n",
    "        masks_to_show = self.val_masks[idxs]\n",
    "        \n",
    "        # Use the model attribute directly, which is set automatically by Keras\n",
    "        predictions = self.model.predict(images_to_show)\n",
    "\n",
    "        # Plot and save the images, masks, and predictions\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i in range(self.num_samples):\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 1)\n",
    "            plt.imshow(images_to_show[i])\n",
    "            plt.title(f'Input Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 2)\n",
    "            plt.imshow(masks_to_show[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'True Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(self.num_samples, 3, i * 3 + 3)\n",
    "            plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'Predicted Mask {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Save the plot to file\n",
    "        plt.savefig(os.path.join(self.save_dir, f'epoch_{epoch+1:02d}_predictions.png'))\n",
    "        plt.close()\n",
    "        print(f\"Saved visualization for epoch {epoch+1}.\")\n",
    "\n",
    "# Instantiate the visualization callback\n",
    "visualization_callback = VisualizationCallback(val_images, val_masks, SAVE_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf12db1-f09b-4aed-a3fd-deb7c5fdc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - self.start_time\n",
    "        print(f\"Training Time: {training_time / 60:.2f} minutes\")\n",
    "\n",
    "# Create an instance of the callback\n",
    "training_time_callback = TrainingTimeCallback()\n",
    "\n",
    "checkpoint = ModelCheckpoint('deeplab_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    batch_size=8,\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint, early_stopping, training_time_callback, visualization_callback],\n",
    "    verbose=1 \n",
    ")\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Save the history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_excel(os.path.join(\"training_history.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b62bf-1b1f-4e93-b3db-496acf5deea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on validation set\n",
    "val_preds = model.predict(val_images)\n",
    "\n",
    "# Convert predictions to binary\n",
    "val_preds_bin = (val_preds > 0.3).astype(int)\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "f1 = f1_score(val_masks.flatten(), val_preds_bin.flatten())\n",
    "\n",
    "# Calculate Mean IoU\n",
    "mean_iou_metric = tf.keras.metrics.MeanIoU(num_classes=2) \n",
    "mean_iou_metric.update_state(val_masks, val_preds_bin)\n",
    "mean_iou = mean_iou_metric.result().numpy()\n",
    "\n",
    "# Save metrics to Excel\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [precision],\n",
    "    'F1 Score': [f1],\n",
    "    'Mean IoU': [mean_iou]\n",
    "})\n",
    "print(f\"Precision: \", precision, \"F1 score: \", f1, \"Mean Iou : \", mean_iou)\n",
    "\n",
    "# Plot training history\n",
    "history_df = pd.read_excel('training_history.xlsx')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as heatmap\n",
    "cm = confusion_matrix(val_masks.flatten(), val_preds_bin.flatten())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize some predictions on validation set\n",
    "for i in range(3):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(val_images[i])\n",
    "    axs[0].set_title('Input Image')\n",
    "    axs[1].imshow(val_masks[i].squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Ground Truth')\n",
    "    axs[2].imshow(val_preds_bin[i].squeeze(), cmap='gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    plt.savefig(f'prediction_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e97ad-3a8f-4c13-99be-3609a104389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = val_images[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c181de6-b6cb-4501-8329-3b727b485d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define input size\n",
    "input_size = (512, 512, 3)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load image\n",
    "    image = load_img(image_path, target_size=target_size[:2])\n",
    "    # Convert to numpy array\n",
    "    image_array = img_to_array(image)\n",
    "    # Normalize the image\n",
    "    image_array = image_array / 255.0\n",
    "    return image_array\n",
    "\n",
    "# Function to save images\n",
    "def save_image(image_array, save_path):\n",
    "    # Convert array to image\n",
    "    image = array_to_img(image_array)\n",
    "    # Save the image\n",
    "    image.save(save_path)\n",
    "\n",
    "# Function to display images\n",
    "def display_images(images, titles=None, cmap='gray'):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(3, 4, i + 1)  # Adjust depending on the number of images\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder = '/home/syam.varnatt/THESIS/Plot_Images(x10,x20)'\n",
    "image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.png')]\n",
    "\n",
    "# Sort the image paths by filenames\n",
    "image_paths = sorted(image_paths)\n",
    "\n",
    "# Select a subset of images\n",
    "image_paths = image_paths[0:]\n",
    "\n",
    "# Predict segmentation masks for each image\n",
    "# Extract image names from paths\n",
    "image_names = [os.path.basename(path) for path in image_paths]\n",
    "\n",
    "# Define the folder path to save images and masks\n",
    "save_folder = '/home/syam.varnatt/THESIS/comparison-model/deeplab/normal/predict_height'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Predict segmentation masks and save images and masks\n",
    "predicted_masks = []\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # Preprocess image\n",
    "    image = preprocess_image(image_path, input_size)\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    # Predict mask\n",
    "    predicted_mask = model.predict(image_batch)[0]\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Save the original image\n",
    "    original_image = img_to_array(load_img(image_path, target_size=input_size[:2])) / 255.0\n",
    "    save_image(original_image, os.path.join(save_folder, f'original_{image_names[i]}'))\n",
    "    \n",
    "    # Save the predicted mask\n",
    "    save_image(predicted_mask, os.path.join(save_folder, f'mask_{image_names[i]}'))\n",
    "    \n",
    "    predicted_masks.append(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9932d60-89f6-4c8e-843a-fa001960fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate inference time for predicting heights\n",
    "\n",
    "# Use a small batch from validation data\n",
    "sample_images = image_batch[:5]\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(sample_images)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(sample_images)\n",
    "print(f\"Average Inference Time per flight height predicted Image: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dce8b-fa97-4b5a-8588-4aca00351afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
